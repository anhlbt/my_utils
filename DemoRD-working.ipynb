{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#import package, define function \n",
    "\n",
    "# Alt + F to expand\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "#define similariry function \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import pymssql\n",
    "#connect to our cluster\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch([{'host': '172.16.3.105', 'port': 9200}])\n",
    "\n",
    "def dotproduct_(v1, v2):\n",
    "    return sum((a*b) for a, b in zip(v1, v2))\n",
    "\n",
    "def dotproduct(v1, v2):\n",
    "    tmp = 0\n",
    "    for a, b in zip(v1, v2):\n",
    "        if a >= 0 and b >= 0:\n",
    "            tmp += (a * b)\n",
    "    return tmp   \n",
    "\n",
    "\n",
    "def length(v):\n",
    "    return math.sqrt(dotproduct(v, v))\n",
    "\n",
    "def similar(v1, v2):\n",
    "    return (dotproduct(v1, v2) / (length(v1) * length(v2)))\n",
    "\n",
    "def length2(v1, v2):\n",
    "    return math.sqrt(sum((a-b)**2 for a, b in zip(v1, v2)))\n",
    "def length3(v1, v2):\n",
    "    tmp = 0\n",
    "    for a, b in zip(v1, v2):\n",
    "        if a >= 0 and b >= 0:\n",
    "            tmp += (a - b)**2\n",
    "    return math.sqrt(tmp)       \n",
    "\n",
    "def rmlistchar(text):\n",
    "    a = re.findall(r\"[^][)\\\"(']\", text)\n",
    "    a = ''.join(a)\n",
    "    return a\n",
    "\n",
    "#remove accents vietnamese\n",
    "def remove_accents(text):\n",
    "    s1 = u'ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚÝàáâãèéêìíòóôõùúýĂăĐđĨĩŨũƠơƯưẠạẢảẤấẦầẨẩẪẫẬậẮắẰằẲẳẴẵẶặẸẹẺẻẼẽẾếỀềỂểỄễỆệỈỉỊịỌọỎỏỐốỒồỔổỖỗỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỳỴỵỶỷỸỹ'\n",
    "    s0 = u'AAAAEEEIIOOOOUUYaaaaeeeiioooouuyAaDdIiUuOoUuAaAaAaAaAaAaAaAaAaAaAaAaEeEeEeEeEeEeEeEeIiIiOoOoOoOoOoOoOoOoOoOoOoOoUuUuUuUuUuUuUuYyYyYyYy'\n",
    "#     s1.encode('utf-8')\n",
    "#     s0.encode('utf-8')\n",
    "    if text == np.nan or text == np.NAN or text == np.NaN:\n",
    "        return text\n",
    "    else:    \n",
    "        s = ''\n",
    "        text = str(text)\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "        for c in text:\n",
    "            if c in s1:\n",
    "                s += s0[s1.index(c)]\n",
    "            else:\n",
    "                s += c\n",
    "        return s.strip()\n",
    "    \n",
    "# remove_accents('Hỗ trợ 4G hôm nãy đi chợi Hỗ trợ Hỗ trợ')   \n",
    "\n",
    "\n",
    "def list_similar(item, numofpro, dataframe):\n",
    "    list_similarity = dataframe[str(item)].sort(inplace = False)[: numofpro + 1]# sort by distance\n",
    "    if str(item) in list_similarity:\n",
    "        return list_similarity.drop([str(item)])\n",
    "    #item_similarity = list_similarity.index.tolist()\n",
    "    #item_similarity = map(lambda x: np.int(x),item_similarity)\n",
    "    #del list_similarity[list_similarity.index(item)]\n",
    "    else:\n",
    "        return list_similarity#, item_similarity[1: numofpro+1]\n",
    "\n",
    "def list_best_sale(category, numofpro, dataframe):\n",
    "    #dataframe = dataframe.fillna(0)\n",
    "#     best_sell = dataframe.loc[np.int(category)].sort_values(ascending = False, inplace = False)\n",
    "#     item_best_sell = best_sell.index.tolist()\n",
    "#     return item_best_sell[1: numofpro+1]# , best_sell\n",
    "    return dataframe.loc[category].sort_values(ascending = False, inplace = False)[0: numofpro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#connect to database\n",
    "'''\n",
    "Created on 27 Mar 2016\n",
    "@author: lbtanh\n",
    "'''\n",
    "import pymssql\n",
    "from os import getenv\n",
    "# -*- coding: utf-8 -*-\n",
    "import tornado.ioloop\n",
    "import tornado.web\n",
    "import tornado.httpserver\n",
    "import tornado.httpclient\n",
    "import tornado.netutil\n",
    "import sys\n",
    "from tornado.ioloop import IOLoop, PeriodicCallback\n",
    "import datetime\n",
    "from threading import Thread\n",
    "import time\n",
    "# from tornado.options import define, options\n",
    "# define(\"port\", default=8897, help=\"run on the given port\", type=int)\n",
    "\n",
    "\n",
    "class Test(tornado.web.RequestHandler):\n",
    "#     def __init__(self):\n",
    "#         self.a = HandClass(self)\n",
    "#     def cong(self, a, b):\n",
    "#         return a+b\n",
    "    \n",
    "    def get(self):\n",
    "        self.write(\"Thegioididong.com\")\n",
    "\n",
    "class TrackingViews(tornado.web.RequestHandler):\n",
    "\n",
    "    def call(self):\n",
    "        return cong(1, 2)\n",
    "    def get(self):\n",
    "#         self.write(str(test))\n",
    "#         c.a.cong(3, 4)\n",
    "        try:\n",
    "            producID = int(self.get_argument('ProductID', None))\n",
    "            num = int(self.get_argument('num', None))\n",
    "            self.write(str(out_graph(info_product, producID, num)))\n",
    "        except Exception as error:\n",
    "            self.write(\"unable to get tracking list by\" + producID +\" Error: \"  + repr(error))          \n",
    "\n",
    "            \n",
    "class Recommend(tornado.web.RequestHandler):\n",
    "    def get(self):\n",
    "        try:\n",
    "            cookie = self.get_argument('Cookie', None)\n",
    "            numofpro = int(self.get_argument('num', None))\n",
    "            numofdays= int(self.get_argument('days', None))\n",
    "            tmp1, tmp2 =list_by_statsmodels(cookie, tracking_DF, numofdays, info_product, numofpro)\n",
    "            self.write('{recommend:'+str(tmp1))\n",
    "            self.write(',mostViews:'+str(tmp2)+ '}')\n",
    "        except Exception as error:\n",
    "            self.write(\"unable to get recommendation list by \" + cookie +\" Error: \"  + repr(error))                 \n",
    "            \n",
    "            \n",
    "def preprocessing_df(dataframe):\n",
    "    tracking_data = dataframe\n",
    "    # preprocessing tracking dataframe\n",
    "    tracking_data = tracking_data.dropna(subset=['ProductID'])\n",
    "#     tracking_data = tracking_data.sort(columns=['COOKIE', 'CREATEDTIME'])\n",
    "    list_product_ID_tracking_data = map(lambda x: int(x), set(tracking_data.ProductID))\n",
    "    df = pd.DataFrame(list_product_ID_tracking_data, columns=['ProductID'])\n",
    "    df['CateID'] = df.ProductID.apply(get_cate_ID_by_proID, args=(0, es, ))\n",
    "#     df['CateID'] = df['CateID'].apply(lambda x: int(x))\n",
    "    df = df.dropna(how = 'any', subset=['CateID'])\n",
    "    df = df[~df.CateID.isin(['3103', '2102'])]\n",
    "    # df['NameCate']= df.CateID.apply(get_name_cate_by_cate_ID)\n",
    "    # df['NameCate_']=df['NameCate'].apply(remove_accents)\n",
    "    tracking_DF = tracking_data.merge(df, how='left', on = 'ProductID')\n",
    "    return tracking_DF            \n",
    "# ================================================================================\n",
    "def cong(a, b):\n",
    "    return a+b            \n",
    "            \n",
    "def connectDB():\n",
    "    server = \"10.1.12.197\"\n",
    "    user = \"rd\"\n",
    "    password = \"rd123456\"\n",
    "    conn = pymssql.connect(server, user, password, \"RD\")\n",
    "    cursor = conn.cursor(as_dict = True)\n",
    "    return cursor\n",
    "# select tracking data\n",
    "\n",
    "def get_DB_tracking_data(num_of_days):\n",
    "    try:\n",
    "        cursor = connectDB()\n",
    "        # tracking_data = 'use RD SELECT [COOKIE] ,[SESSION],[CREATEDTIME],[URL]  FROM [RD].[dbo].[TRACKINGDATA] where SITEID = 8'\n",
    "        tracking_data = 'use RD SELECT [ID], [COOKIE] ,[SESSION],[CREATEDTIME], \\\n",
    "        [RD].[dbo].[TRACKINGDATA].[URL], vuivui.Product.ProductID \\\n",
    "        FROM [RD].[dbo].[TRACKINGDATA] \\\n",
    "        left join [RD].[vuivui].[Product] on vuivui.Product.RealUrl = RD.dbo.TRACKINGDATA.URL \\\n",
    "        where SITEID = 8 and DATEDIFF(day,CREATEDTIME, GETDATE()) <= %d' %(num_of_days)\n",
    "        cursor.execute(tracking_data)\n",
    "        tracking_data = cursor.fetchall()\n",
    "        tracking_data = pd.DataFrame(tracking_data)\n",
    "        cursor.close()\n",
    "        current_ID = int(tracking_data.tail(1).ID.values)\n",
    "    except:\n",
    "        pass\n",
    "    return tracking_data, current_ID\n",
    "\n",
    "    \n",
    "def get_DB_current(current_ID):\n",
    "    cursor = connectDB()\n",
    "    current_data = 'use RD SELECT [ID], [COOKIE] ,[SESSION],[CREATEDTIME], \\\n",
    "    [RD].[dbo].[TRACKINGDATA].[URL], vuivui.Product.ProductID \\\n",
    "    FROM [RD].[dbo].[TRACKINGDATA] \\\n",
    "    left join [RD].[vuivui].[Product] on vuivui.Product.RealUrl = RD.dbo.TRACKINGDATA.URL \\\n",
    "    where SITEID = 8 and ID > %d' %(current_ID)\n",
    "    cursor.execute(current_data)\n",
    "    current_data = cursor.fetchall()\n",
    "    current_data = pd.DataFrame(current_data)\n",
    "    cursor.close()\n",
    "    if current_data.shape[0] == 0:\n",
    "        return current_data, current_ID\n",
    "    current_ID = int(current_data.tail(1).ID.values)\n",
    "    return current_data, current_ID\n",
    "\n",
    "# ================================================================================\n",
    "\n",
    "\n",
    "def get_cate_ID_by_proID(productID, position, es):\n",
    "    try:\n",
    "        #connect to our cluster\n",
    "        from elasticsearch import Elasticsearch\n",
    "        es = Elasticsearch([{'host': '172.16.3.105', 'port': 9200}])\n",
    "        # res = requests.get('http://172.16.3.105:9200/index_product/product/86734')\n",
    "        # print(res.content)\n",
    "        pathCate = es.get(index=\"index_product\", doc_type=\"product\", id=str(int(productID)))['_source']['categoryPath']\n",
    "        listCate = pathCate.split(\" \")\n",
    "        return listCate[position]\n",
    "    except Exception as error:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n",
    "def get_name_cate_by_cate_ID(cate_ID):\n",
    "    try: \n",
    "        url = 'http://webservice.vuivui.com/productsvc.asmx/GetProductCategoryByCate?intSiteID=8&intCategoryID='\n",
    "        url = url + str(int(cate_ID))\n",
    "        res = requests.get(url)\n",
    "        xml = ET.fromstring(res.content)\n",
    "        return xml[0][1].text\n",
    "    except Exception as error:\n",
    "        return \"\"\n",
    "# ================================================================================\n",
    "\n",
    "def get_DB_test():\n",
    "    cursor = connectDB()\n",
    "    hot_product = \"SELECT TOP 1 *  FROM [RD].[dbo].[TRACKINGDATA] where CREATEDTIME >= '2017-05-11'  ORDER BY id DESC\"    \n",
    "    cursor.execute(hot_product)\n",
    "    hot_product = cursor.fetchall()\n",
    "    hot_product = pd.DataFrame(hot_product)\n",
    "    cursor.close()\n",
    "    return hot_product\n",
    "\n",
    "\n",
    "def get_DB_hot_product():\n",
    "    cursor = connectDB()\n",
    "    hot_product = 'use RD SELECT RD.dbo.TRACKINGDATASUMMARIZE.ProductID, Price, SUM(Value) as Views, vuivui.Product.CategoryID FROM RD.dbo.TRACKINGDATASUMMARIZE join vuivui.Product on vuivui.Product.ProductID = RD.dbo.TRACKINGDATASUMMARIZE.ProductID where Type = 1  group by RD.dbo.TRACKINGDATASUMMARIZE.ProductID, RefProductID, Price, ProductName, vuivui.Product.CategoryID order by vuivui.Product.CategoryID,SUM(Value) desc'\n",
    "    cursor.execute(hot_product)\n",
    "    hot_product = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return pd.DataFrame(hot_product)\n",
    "\n",
    "\n",
    "# select tracking table\n",
    "def get_DB_views(info_product):\n",
    "    cursor = connectDB()\n",
    "    sql = \"use RD DECLARE @day INT=  CAST(convert(varchar(8), GETDATE(), 112) AS VARCHAR(8)) \\\n",
    "    +CAST(DATEPART(HOUR, GETDATE()) AS VARCHAR(2)); \\\n",
    "    SELECT RD.dbo.TRACKINGDATASUMMARIZE.ProductID, RefProductID, Price, \\\n",
    "    ProductName, SUM(Value) as Views, vuivui.Product.CategoryID \\\n",
    "    FROM RD.dbo.TRACKINGDATASUMMARIZE \\\n",
    "    join vuivui.Product on vuivui.Product.ProductID = RD.dbo.TRACKINGDATASUMMARIZE.RefProductID \\\n",
    "    where Type = 4 and @day - DayKey < 20000 \\\n",
    "    group by RD.dbo.TRACKINGDATASUMMARIZE.ProductID, RefProductID, \\\n",
    "    Price, ProductName, vuivui.Product.CategoryID \\\n",
    "    order by SUM(Value) desc\"\n",
    "    \n",
    "    cursor.execute(sql)\n",
    "    a = cursor.fetchall()\n",
    "    #preprocessing\n",
    "    testA = pd.DataFrame(a)\n",
    "    testA = testA[testA['Price'] != -1]\n",
    "    testA = testA[testA['Price'] != 0]\n",
    "    #preprocessing\n",
    "    testA = pd.merge(testA, info_product.iloc[:,],how = 'left', left_on = 'ProductID',right_on = 'ProductID')\n",
    "    testA.rename(columns={'Price_x':'RefPrice', 'Price_y':'ProductPrice', 'CategoryID_x':'RefCategoryID', 'CategoryID_y':'CategoryID', 'ProductName_x':'RefProductName', 'ProductName_y':'ProductName'}, inplace=True)\n",
    "\n",
    "    # drop NaN value in columns RefProductID\n",
    "    testA = testA.dropna(axis = 0, how='any', subset = ['RefProductID', 'ProductID'])\n",
    "    testA = testA.loc[:,['ProductID', 'ProductName', 'ProductPrice', 'RefProductID', 'RefProductName','RefPrice', 'Views', 'CategoryID', 'RefCategoryID']]\n",
    "\n",
    "    testA[['ProductName', 'RefProductName']] = testA[['ProductName', 'RefProductName']].applymap(remove_accents)\n",
    "    testA[['ProductName', 'RefProductName']] = testA[['ProductName', 'RefProductName']].applymap(rmlistchar)\n",
    "        #     test = demo[['ProductID','RefProductID', 'Views']]\n",
    "    return testA\n",
    "\n",
    "#get info product\n",
    "def get_DB_all_product():\n",
    "    try:\n",
    "        cursor = connectDB()\n",
    "        produc_cate = 'use RD SELECT [ProductID] ,[ProductName] ,[Price] \\\n",
    "        FROM [RD].[vuivui].[Product]'\n",
    "        cursor.execute(produc_cate)\n",
    "        info_product = cursor.fetchall()\n",
    "        info_product = pd.DataFrame(info_product)\n",
    "        info_product  = info_product.drop_duplicates()\n",
    "        cursor.close()\n",
    "        info_product['CategoryID'] = info_product.ProductID.apply(get_cate_ID_by_proID, args=(-1, es, ))\n",
    "        info_product = info_product[info_product['CategoryID'] > 1]\n",
    "        info_product['CategoryID'] = info_product.CategoryID.apply(lambda x: int(x))\n",
    "    except:\n",
    "        pass\n",
    "    return info_product\n",
    "# input: dataframe testA\n",
    "# create graph by ID\n",
    "def create_graph(test):\n",
    "    g = nx.DiGraph((raw['ProductID'], raw['RefProductID'], {'weight': raw['Views']}) for index, raw in test.iterrows())\n",
    "    return g\n",
    "\n",
    "# create graph by name\n",
    "def create_graph1(test):\n",
    "    g = nx.DiGraph((raw['ProductName'], raw['RefProductName'], {'weight': raw['Views'], 'label':str(raw['Views'])}) for index, raw in test.iterrows())\n",
    "    return g\n",
    "\n",
    "#     def inital_graph(self, categoryID, testA):\n",
    "#         for cate in categoryID:\n",
    "#             exec('cate_'+str(cate)+ '= testA[(testA.CategoryID =='+str(cate)+ ') & (testA.RefCategoryID ==' +str(cate)+')]')\n",
    "#             exec('global g_'+str(cate))\n",
    "#             exec('g_'+str(cate)+ '= create_graph(cate_'+str(cate)+')')\n",
    "#         return    \n",
    "\n",
    "# recommended by tracking data\n",
    "def out_graph(info_product, productid, numofpro, typegraph = 'out'):\n",
    "    # return list of tuples which was sorted by weight out edges\n",
    "    try:\n",
    "        cate_pro = int(info_product['CategoryID'][info_product['ProductID']==productid])\n",
    "    #     df = df[df['CategoryID']==cate_pro]\n",
    "    #     g = create_graph(df[:-1])\n",
    "        exec('g=g_'+str(cate_pro))\n",
    "        if typegraph == 'out':\n",
    "            if productid in pd.DataFrame(g.out_edges()).iloc[:][0].tolist():\n",
    "                df_weight = pd.DataFrame(g.out_edges(productid, data='weight'))\n",
    "                df_weight.columns = ['ProductID','RefProductID', 'Views']\n",
    "                df_weight=df_weight.sort(columns = ['Views'], ascending = False)[:numofpro]\n",
    "            else:\n",
    "                return []\n",
    "    #         tmp = testA[testA.columns][testA.RefProductID.isin(df_weight['RefProductID'])]\n",
    "    #         return tmp[tmp.ProductID == productid]\n",
    "        else:\n",
    "            if productid in pd.DataFrame(g.out_edges()).iloc[:][0].tolist():\n",
    "                df_weight = pd.DataFrame(g.in_edges(productid, data='weight'))\n",
    "                df_weight.columns = ['ProductID','RefProductID', 'Views']\n",
    "                df_weight=df_weight.sort(columns = ['Views'], ascending = False)[:numofpro]\n",
    "            else:\n",
    "                return []\n",
    "    #         tmp = testA[testA.columns][testA.ProductID.isin(df_weight['ProductID'])]\n",
    "    #         return tmp[tmp.RefProductID == productid]\n",
    "        #sorted by \n",
    "        return df_weight[['RefProductID', 'Views']].to_json(orient='values') \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# it can work with lambda function\n",
    "'''\n",
    "cookie: cookie of user\n",
    "tracking_DF: dataframe tracking data\n",
    "ndays: number of day to processing\n",
    "'''\n",
    "def list_by_statsmodels(cookie, tracking_DF, ndays, info_product, numofpro):\n",
    "    tmp = tracking_DF[tracking_DF['COOKIE']==cookie]\n",
    "#     f = {'SESSION':['nunique'], 'ProductID':['nunique', 'count'], 'CateID': ['nunique']}\n",
    "    f = {'SESSION':['nunique'],'ProductID':['count']}\n",
    "    stat_tracking = tmp.groupby(['COOKIE','ProductID']).agg(f)\n",
    "    stat_tracking = pd.DataFrame(stat_tracking)\n",
    "    stat_tracking = stat_tracking.reset_index()\n",
    "    stat_tracking.columns = ['COOKIE', 'ProductID', 'Count_Session', 'Views']\n",
    "    list_relative = list(stat_tracking[stat_tracking.Count_Session == 2].ProductID.values)\n",
    "    list_relative.extend(list(stat_tracking[stat_tracking.Views >= 3].ProductID.values))\n",
    "    list_recommend = list(stat_tracking[stat_tracking.Count_Session > 2].ProductID.values)\n",
    "    list_recommend.extend(list(stat_tracking[stat_tracking.Views > 3].ProductID.values))\n",
    "    list_recommend = map(lambda x: int(x), list_recommend)\n",
    "    \n",
    "    df_tmp = tracking_DF\n",
    "    df_tmp['DAYS'] = datetime.date.today() - df_tmp.CREATEDTIME\n",
    "    tracking_DF_ndays = df_tmp[df_tmp['DAYS'] <= datetime.timedelta(ndays)]\n",
    "    list_tmp = unique_list_order(tracking_DF_ndays[tracking_DF_ndays['COOKIE']==cookie].ProductID.values)\n",
    "    list_relative.extend(list_tmp)\n",
    "    list_relative = map(lambda x: int(x), list_relative)\n",
    "    list_relative=out_graph_by_list(info_product, list(set(list_relative)), numofpro)\n",
    "    list_relative = map(lambda x: int(x), list_relative)\n",
    "    return  list_relative, list(set(list_recommend))    \n",
    "    \n",
    "    \n",
    "def unique_list_order(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def unique_list_order_(list_):\n",
    "    list_ = np.array(list_)\n",
    "    _, idx = np.unique(list_, return_index=True)\n",
    "    return list_[np.sort(idx)]\n",
    "# return list of recommended product by list viewed product\n",
    "def out_graph_by_list(info_product, list_productid, numofpro):\n",
    "    try:\n",
    "        list_results = []\n",
    "        for productid in list_productid:\n",
    "            cate_pro = int(info_product['CategoryID'][info_product['ProductID']==productid])\n",
    "            exec('g=g_'+str(cate_pro))\n",
    "            if productid in pd.DataFrame(g.out_edges()).iloc[:][0].tolist():\n",
    "                df_weight = pd.DataFrame(g.out_edges(productid, data='weight'))\n",
    "                df_weight.columns = ['ProductID','RefProductID', 'Views']\n",
    "                df_weight=df_weight.sort(columns = ['Views'], ascending = False)[:numofpro]\n",
    "                list_results.extend(df_weight.RefProductID.values)\n",
    "                list_results = unique_list_order(list_results)\n",
    "    except:\n",
    "        pass\n",
    "    return list_results\n",
    "\n",
    "\n",
    "\n",
    "def inital_():\n",
    "    try:\n",
    "    #     print datetime.datetime.now()\n",
    "        global info_product\n",
    "        global testA\n",
    "        global categoryID\n",
    "        info_product = get_DB_all_product()\n",
    "        testA = get_DB_views(info_product)\n",
    "        categoryID = info_product.CategoryID.unique().tolist()\n",
    "        #         self.g_all = create_graph(testA)\n",
    "        for cate in categoryID:\n",
    "            exec('cate_'+str(cate)+ '= testA[(testA.CategoryID =='+str(cate)+ ') & (testA.RefCategoryID ==' +str(cate)+')]', globals())\n",
    "            exec('g_'+str(cate)+ '= create_graph(cate_'+str(cate)+')', globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "class Application(tornado.web.Application):\n",
    "    def __init__(self):\n",
    "        handlers = [\n",
    "                  (r\"/trackingview\", TrackingViews),\n",
    "                (r\"/recommend\", Recommend),\n",
    "                  (r\"/\", Test),              \n",
    "        ]\n",
    "        settings = {}\n",
    "        tornado.web.Application.__init__(self, handlers, **settings)\n",
    "\n",
    "\n",
    "def thread_get_resys_by_views(threadname):\n",
    "    while 1:\n",
    "        inital_()\n",
    "        time.sleep(86400)   \n",
    "\n",
    "def thread1(threadname):\n",
    "    #global a       # Optional if you treat a as read-only\n",
    "    while 1:\n",
    "        http_server = tornado.httpserver.HTTPServer(Application())\n",
    "        http_server.listen(8808)\n",
    "\n",
    "def inital_test():\n",
    "    global test\n",
    "    test = get_DB_test()\n",
    "#     time.sleep(2)\n",
    "def thread3(threadname):\n",
    "#     global test\n",
    "    while 1:\n",
    "        inital_test()\n",
    "        time.sleep(3)  \n",
    "\n",
    "def tracking_get_DB():\n",
    "    global tracking_DF, current_ID\n",
    "    tracking_data, current_ID = get_DB_tracking_data(14)\n",
    "    tracking_DF = preprocessing_df(tracking_data)\n",
    "    \n",
    "def thread_tracking_get_DB(threadname):\n",
    "    while 1:\n",
    "        tracking_get_DB()\n",
    "        time.sleep(1000)\n",
    "\n",
    "def tracking_update_DB():\n",
    "    global current_DB, current_ID, tracking_DF\n",
    "    current_DB, current_ID = get_DB_current(current_ID)\n",
    "    if current_DB.shape[0]!=0:\n",
    "#         tracking_data = tracking_data.append(current_DB)\n",
    "        current_DB = preprocessing_df(current_DB)\n",
    "        tracking_DF=tracking_DF.append(current_DB)\n",
    "\n",
    "def thread_tracking_update_DB(threadname):\n",
    "    while 1:\n",
    "        tracking_update_DB()\n",
    "        time.sleep(2)  \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "#     inital_()\n",
    "#     http_server = tornado.httpserver.HTTPServer(Application())\n",
    "#     http_server.listen(8808)\n",
    "#     PeriodicCallback(inital_, 4*60*1000).start()\n",
    "    info_product = 0\n",
    "    testA = 0\n",
    "    categoryID = 0\n",
    "    test = 0\n",
    "    current_DB = 0\n",
    "    tracking_DF = 0\n",
    "    current_ID = 0\n",
    "#     tracking_data = 0\n",
    "    \n",
    "    thread1 = Thread( target=thread1, args=(\"Thread-1\", ) )\n",
    "    thread_get_resys_by_views = Thread( target=thread_get_resys_by_views, args=(\"Thread get item views\", ) )\n",
    "    thread3 = Thread( target=thread3, args=(\"Thread-3\", ) )\n",
    "    thread_tracking_get_DB = Thread( target=thread_tracking_get_DB, args=(\"Thread get all tracking data DB\", ))\n",
    "    thread_tracking_update_DB = Thread( target=thread_tracking_update_DB, args=(\"Thread update tracking data DB\", ))\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    thread1.start()\n",
    "    time.sleep(1)\n",
    "    thread_get_resys_by_views.start()\n",
    "    time.sleep(2)\n",
    "    time1 = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    tracking_get_DB()\n",
    "#     thread_tracking_get_DB.start()\n",
    "#     time.sleep(250)\n",
    "    time.sleep(1)\n",
    "    thread_tracking_update_DB.start()\n",
    "    \n",
    "    time2 = time.time() - start\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tornado.ioloop.IOLoop.instance().stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_product.to_csv('info_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_DF.to_csv('tracking_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_DB_from_file():\n",
    "    global tracking_DF, current_ID\n",
    "    tracking_DF = pd.read_csv('tracking_DF.csv')\n",
    "    current_ID = int(tracking_DF.tail(1).ID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_DB_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268123358"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.295608520507812e-05"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a9d84f26-0e54-4c24-b40e-1f6713987677\n",
    "# 2b05443b-ab18-4437-9090-c434aba3d7da\n",
    "def get_basket_customer():\n",
    "    cursor = connectDB()\n",
    "    basket_customer = \"use RD SELECT ID, SESSION, PRODUCTID, NUMBERITEM FROM [RD].[dbo].[TRACKINGDATA] where SITEID = 8 and PRODUCTID != -1 and [COOKIE] = 'a9d84f26-0e54-4c24-b40e-1f6713987677' order by ID desc\"    \n",
    "    cursor.execute(basket_customer)\n",
    "    basket_customer = cursor.fetchall()\n",
    "    basket_customer = pd.DataFrame(basket_customer)\n",
    "    cursor.close()\n",
    "    return basket_customer\n",
    "\n",
    "def get_record():\n",
    "    # filter by session\n",
    "    # list_order_id = []\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    basket_customer =  get_basket_customer()\n",
    "    for session in list(basket_customer.SESSION.unique()):\n",
    "        basket_customer_session = basket_customer[basket_customer['SESSION']==session]\n",
    "        data = basket_customer_session.drop_duplicates(subset = ['PRODUCTID'])\n",
    "        for item in list(data[data['NUMBERITEM']< 0].PRODUCTID):\n",
    "            data.loc[data.PRODUCTID == item, 'NUMBERITEM'] = basket_customer_session[basket_customer_session['PRODUCTID']==item].NUMBERITEM.sum()\n",
    "        record = data[data['NUMBERITEM']>0]\n",
    "        if record.shape[0] > 0:\n",
    "            record1 = frozenset(record.PRODUCTID)\n",
    "            yield record1\n",
    "            \n",
    "#             record = list(record.PRODUCTID.unique())\n",
    "#             list_order_id.append(record)  \n",
    "    # write to file record       \n",
    "    # with open(\"list_to_file1.txt\", \"w\") as output:\n",
    "    #     for item in list_order_id:\n",
    "    #         output.write('%s\\n' %','.join(map(str,item)))    \n",
    "\n",
    "\n",
    "start = time.time()\n",
    "aaa = get_record()\n",
    "time.time() - start    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for i in aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (x*x for x in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'107686',\n",
       "           '76413',\n",
       "           '76488',\n",
       "           '77230',\n",
       "           '77718',\n",
       "           '79562',\n",
       "           '79571',\n",
       "           '79710',\n",
       "           '81658',\n",
       "           '83935',\n",
       "           '90968',\n",
       "           '91905'})"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpa.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getItemSetTransactionList(data_iterator):\n",
    "        transactionList = list()\n",
    "        itemSet = set()\n",
    "        for record in data_iterator:\n",
    "            transaction = frozenset(record)\n",
    "            transactionList.append(transaction)\n",
    "            for item in transaction:\n",
    "                itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "        return itemSet, transactionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemSet, transactionList = getItemSetTransactionList(tmpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'82640'}),\n",
       " frozenset({'105771'}),\n",
       " frozenset({'96034'}),\n",
       " frozenset({'106249'}),\n",
       " frozenset({'83244'}),\n",
       " frozenset({'105139'}),\n",
       " frozenset({'76514'}),\n",
       " frozenset({'96096'}),\n",
       " frozenset({'81422'}),\n",
       " frozenset({'77146'}),\n",
       " frozenset({'84857'}),\n",
       " frozenset({'104896'}),\n",
       " frozenset({'79710'}),\n",
       " frozenset({'96416'}),\n",
       " frozenset({'108602'}),\n",
       " frozenset({'79490'}),\n",
       " frozenset({'81752'}),\n",
       " frozenset({'76446'}),\n",
       " frozenset({'85679'}),\n",
       " frozenset({'77154'}),\n",
       " frozenset({'85820'}),\n",
       " frozenset({'90520'}),\n",
       " frozenset({'86003'}),\n",
       " frozenset({'79832'}),\n",
       " frozenset({'79324'}),\n",
       " frozenset({'93229'}),\n",
       " frozenset({'79571'}),\n",
       " frozenset({'80570'}),\n",
       " frozenset({'103397'}),\n",
       " frozenset({'83949'}),\n",
       " frozenset({'84813'}),\n",
       " frozenset({'85984'}),\n",
       " frozenset({'79823'}),\n",
       " frozenset({'89090'}),\n",
       " frozenset({'76929'}),\n",
       " frozenset({'82178'}),\n",
       " frozenset({'82208'}),\n",
       " frozenset({'88360'}),\n",
       " frozenset({'91905'}),\n",
       " frozenset({'96411'}),\n",
       " frozenset({'102587'}),\n",
       " frozenset({'76356'}),\n",
       " frozenset({'76413'}),\n",
       " frozenset({'79426'}),\n",
       " frozenset({'89066'}),\n",
       " frozenset({'81846'}),\n",
       " frozenset({'89432'}),\n",
       " frozenset({'83120'}),\n",
       " frozenset({'76699'}),\n",
       " frozenset({'79338'}),\n",
       " frozenset({'91752'}),\n",
       " frozenset({'81563'}),\n",
       " frozenset({'77718'}),\n",
       " frozenset({'76409'}),\n",
       " frozenset({'79968'}),\n",
       " frozenset({'88872'}),\n",
       " frozenset({'100709'}),\n",
       " frozenset({'76527'}),\n",
       " frozenset({'76334'}),\n",
       " frozenset({'91587'}),\n",
       " frozenset({'79954'}),\n",
       " frozenset({'83686'}),\n",
       " frozenset({'76939'}),\n",
       " frozenset({'85164'}),\n",
       " frozenset({'93535'}),\n",
       " frozenset({'79336'}),\n",
       " frozenset({'79562'}),\n",
       " frozenset({'83685'}),\n",
       " frozenset({'86208'}),\n",
       " frozenset({'97314'}),\n",
       " frozenset({'80617'}),\n",
       " frozenset({'89173'}),\n",
       " frozenset({'78254'}),\n",
       " frozenset({'106480'}),\n",
       " frozenset({'79849'}),\n",
       " frozenset({'81304'}),\n",
       " frozenset({'86201'}),\n",
       " frozenset({'96415'}),\n",
       " frozenset({'79630'}),\n",
       " frozenset({'86753'}),\n",
       " frozenset({'96127'}),\n",
       " frozenset({'107896'}),\n",
       " frozenset({'86310'}),\n",
       " frozenset({'106436'}),\n",
       " frozenset({'89147'}),\n",
       " frozenset({'82099'}),\n",
       " frozenset({'79487'}),\n",
       " frozenset({'105778'}),\n",
       " frozenset({'106303'}),\n",
       " frozenset({'80578'}),\n",
       " frozenset({'100097'}),\n",
       " frozenset({'76498'}),\n",
       " frozenset({'96086'}),\n",
       " frozenset({'79866'}),\n",
       " frozenset({'79269'}),\n",
       " frozenset({'76826'}),\n",
       " frozenset({'103714'}),\n",
       " frozenset({'71754'}),\n",
       " frozenset({'76350'}),\n",
       " frozenset({'89730'}),\n",
       " frozenset({'76094'}),\n",
       " frozenset({'77230'}),\n",
       " frozenset({'83682'}),\n",
       " frozenset({'79734'}),\n",
       " frozenset({'78886'}),\n",
       " frozenset({'74480'}),\n",
       " frozenset({'81658'}),\n",
       " frozenset({'83449'}),\n",
       " frozenset({'79947'}),\n",
       " frozenset({'80146'}),\n",
       " frozenset({'78455'}),\n",
       " frozenset({'76522'}),\n",
       " frozenset({'96764'}),\n",
       " frozenset({'104764'}),\n",
       " frozenset({'76352'}),\n",
       " frozenset({'106247'}),\n",
       " frozenset({'76477'}),\n",
       " frozenset({'99101'}),\n",
       " frozenset({'89293'}),\n",
       " frozenset({'77640'}),\n",
       " frozenset({'87545'}),\n",
       " frozenset({'85234'}),\n",
       " frozenset({'82658'}),\n",
       " frozenset({'82563'}),\n",
       " frozenset({'101100'}),\n",
       " frozenset({'83445'}),\n",
       " frozenset({'77138'}),\n",
       " frozenset({'106226'}),\n",
       " frozenset({'96439'}),\n",
       " frozenset({'81185'}),\n",
       " frozenset({'99058'}),\n",
       " frozenset({'81788'}),\n",
       " frozenset({'78631'}),\n",
       " frozenset({'93664'}),\n",
       " frozenset({'75626'}),\n",
       " frozenset({'78450'}),\n",
       " frozenset({'81404'}),\n",
       " frozenset({'76160'}),\n",
       " frozenset({'79245'}),\n",
       " frozenset({'96064'}),\n",
       " frozenset({'104480'}),\n",
       " frozenset({'71832'}),\n",
       " frozenset({'82560'}),\n",
       " frozenset({'91825'}),\n",
       " frozenset({'79341'}),\n",
       " frozenset({'88357'}),\n",
       " frozenset({'91400'}),\n",
       " frozenset({'96881'}),\n",
       " frozenset({'105261'}),\n",
       " frozenset({'76520'}),\n",
       " frozenset({'79270'}),\n",
       " frozenset({'104294'}),\n",
       " frozenset({'84989'}),\n",
       " frozenset({'101832'}),\n",
       " frozenset({'106479'}),\n",
       " frozenset({'106233'}),\n",
       " frozenset({'82701'}),\n",
       " frozenset({'76014'}),\n",
       " frozenset({'90701'}),\n",
       " frozenset({'88703'}),\n",
       " frozenset({'90968'}),\n",
       " frozenset({'107686'}),\n",
       " frozenset({'106532'}),\n",
       " frozenset({'74017'}),\n",
       " frozenset({'77622'}),\n",
       " frozenset({'93494'}),\n",
       " frozenset({'79623'}),\n",
       " frozenset({'105158'}),\n",
       " frozenset({'88471'}),\n",
       " frozenset({'85565'}),\n",
       " frozenset({'83935'}),\n",
       " frozenset({'79943'}),\n",
       " frozenset({'76491'}),\n",
       " frozenset({'95487'}),\n",
       " frozenset({'90668'}),\n",
       " frozenset({'89855'}),\n",
       " frozenset({'85567'}),\n",
       " frozenset({'76848'}),\n",
       " frozenset({'86423'}),\n",
       " frozenset({'95112'}),\n",
       " frozenset({'93994'}),\n",
       " frozenset({'78439'}),\n",
       " frozenset({'76488'}),\n",
       " frozenset({'77144'}),\n",
       " frozenset({'83657'}),\n",
       " frozenset({'78557'}),\n",
       " frozenset({'92883'}),\n",
       " frozenset({'77009'}),\n",
       " frozenset({'77145'}),\n",
       " frozenset({'80771'}),\n",
       " frozenset({'85687'}),\n",
       " frozenset({'91849'}),\n",
       " frozenset({'104839'}),\n",
       " frozenset({'77032'}),\n",
       " frozenset({'93768'}),\n",
       " frozenset({'82899'}),\n",
       " frozenset({'98901'}),\n",
       " frozenset({'79812'}),\n",
       " frozenset({'101111'}),\n",
       " frozenset({'79343'}),\n",
       " frozenset({'76295'}),\n",
       " frozenset({'80553'}),\n",
       " frozenset({'104709'}),\n",
       " frozenset({'76479'}),\n",
       " frozenset({'77107'}),\n",
       " frozenset({'81371'}),\n",
       " frozenset({'84327'}),\n",
       " frozenset({'76495'}),\n",
       " frozenset({'101424'}),\n",
       " frozenset({'96224'}),\n",
       " frozenset({'88280'}),\n",
       " frozenset({'76330'}),\n",
       " frozenset({'76376'}),\n",
       " frozenset({'89852'}),\n",
       " frozenset({'60546'}),\n",
       " frozenset({'83842'}),\n",
       " frozenset({'89410'}),\n",
       " frozenset({'79175'}),\n",
       " frozenset({'83684'}),\n",
       " frozenset({'90767'}),\n",
       " frozenset({'79804'}),\n",
       " frozenset({'108429'}),\n",
       " frozenset({'83365'}),\n",
       " frozenset({'88581'}),\n",
       " frozenset({'84284'}),\n",
       " frozenset({'77738'}),\n",
       " frozenset({'80968'}),\n",
       " frozenset({'84814'}),\n",
       " frozenset({'96285'}),\n",
       " frozenset({'84180'}),\n",
       " frozenset({'104707'}),\n",
       " frozenset({'83853'})}"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'105139'})"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemSet.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# tracking_DF[tracking_DF['COOKIE']=='2b05443b-ab18-4437-9090-c434aba3d7da']\n",
    "# time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph(info_product, 91060, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list_productid = [84801, 90772, 88268]\n",
    "out_graph_by_list(info_product, list_productid, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get history by cookie from DATATRACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tree category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get xml file\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "url2 = 'http://webservice.vuivui.com/productsvc.asmx/GetProductCategoryByCate?intSiteID=8&intCategoryID=166'\n",
    "url = 'http://webservice.thegioididong.com/cmsservice/ProductSvc.asmx/GetAllProductCategory?intIsActived=1&intSiteID=8&strLanguageID=vi-VN'\n",
    "res = requests.get(url, timeout=10)\n",
    "xml = ET.fromstring(res.content)\n",
    "\n",
    "\n",
    "\n",
    "# get list category path of product \n",
    "list_path = []\n",
    "for child in xml.findall('{http://tempuri.org/}ProductCategoryBO'):\n",
    "    tmp = child.find('{http://tempuri.org/}NodeTree').text\n",
    "    list_path.append(tmp)\n",
    "    \n",
    "# delete ',' and convert to int\n",
    "results = [[int(x) for x in path[1:-1].split(',')] for path in list_path if ',' in path[1:-1]]    \n",
    "\n",
    "\n",
    "# to create graph\n",
    "'''\n",
    "G = nx.DiGraph()\n",
    "for node in results:  \n",
    "    a = [(node[i], node[i + 1]) for i in xrange(len(node) - 1)]\n",
    "    for i in xrange(len(node) - 1):\n",
    "        G.add_edge(node[i],node[i + 1])\n",
    "'''  \n",
    "G = nx.DiGraph()\n",
    "for node in results: \n",
    "    G.add_path(node)\n",
    "# nx.draw(G,with_labels = True)\n",
    "# from matplotlib import pylab as plt\n",
    "# plt.show()  \n",
    "\n",
    "\n",
    "nx.nx_pydot.write_dot(G, 'graph_path_category.txt')\n",
    "# run in window\n",
    "# !os.system(\"dot -Tpng -ograph_path_category.png graph_path_category.txt\")\n",
    "\n",
    "\n",
    "df_path_category = pd.DataFrame(G.edges())\n",
    "df_path_category.columns = ['source_ID', 'destination_ID']\n",
    "df_path_category['source_name'] = df_path_category.source_ID.apply(get_name_cate_by_cate_ID)\n",
    "df_path_category['destination_name'] = df_path_category.destination_ID.apply(get_name_cate_by_cate_ID)\n",
    "# df_path_category.to_csv('df_path_category.csv')\n",
    "\n",
    "\n",
    "# create graph by dataframe\n",
    "G1 = nx.DiGraph((raw['source_name']+'\\n'+str(raw['source_ID']), raw['destination_name']+'\\n'+str(raw['destination_ID'])) for index, raw in df_path_category.iterrows())\n",
    "# export text file to draw the graph by command line\n",
    "nx.nx_pydot.write_dot(G1, 'graph_path_category_name.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thay doi thu tu cate theo cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from rediscluster import StrictRedisCluster\n",
    "# Requires at least one node for cluster discovery. Multiple nodes is recommended.\n",
    "startup_nodes = [{\"host\": \"10.1.12.30\", \"port\": \"16379\"}]\n",
    "rc = StrictRedisCluster(startup_nodes=startup_nodes, decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1L"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.hset('hash_test', 'key1', 'value1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method StrictRedisCluster.client_list of StrictRedisCluster<10.1.12.30:16379>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
